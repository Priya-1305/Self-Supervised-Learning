{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import CIFAR10"
      ],
      "metadata": {
        "id": "oXOOtC850NKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DualAugment:\n",
        "    def __init__(self):\n",
        "        self.aug = transforms.Compose([\n",
        "            transforms.RandomResizedCrop(32, scale=(0.2, 1.0)),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomApply([transforms.ColorJitter(0.8,0.8,0.8,0.2)], p=0.8),\n",
        "            transforms.RandomGrayscale(p=0.2),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.4914,0.4822,0.4465],\n",
        "                                 std=[0.2023,0.1994,0.2010]),\n",
        "        ])\n",
        "    def __call__(self, x):\n",
        "        return self.aug(x), self.aug(x)\n",
        "\n",
        "train_dataset = CIFAR10(root='./data', train=True, download=True,\n",
        "                        transform=DualAugment())\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True,\n",
        "                          num_workers=2, pin_memory=True, drop_last=True)\n"
      ],
      "metadata": {
        "id": "8C7l5enG0R04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_c, out_c, stride=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_c, out_c, 3, stride, 1, bias=False)\n",
        "        self.bn1   = nn.BatchNorm2d(out_c)\n",
        "        self.conv2 = nn.Conv2d(out_c, out_c, 3, 1, 1, bias=False)\n",
        "        self.bn2   = nn.BatchNorm2d(out_c)\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_c != out_c:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_c, out_c, 1, stride, bias=False),\n",
        "                nn.BatchNorm2d(out_c)\n",
        "            )\n",
        "    def forward(self, x):\n",
        "        out = torch.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        return torch.relu(out)"
      ],
      "metadata": {
        "id": "-1WW0hSf0XrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n",
        "        self.bn1   = nn.BatchNorm2d(64)\n",
        "        self.l1 = nn.Sequential(BasicBlock(64,64), BasicBlock(64,64))\n",
        "        self.l2 = nn.Sequential(BasicBlock(64,128,2), BasicBlock(128,128))\n",
        "        self.l3 = nn.Sequential(BasicBlock(128,256,2), BasicBlock(256,256))\n",
        "        self.l4 = nn.Sequential(BasicBlock(256,512,2), BasicBlock(512,512))\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.l1(x); x = self.l2(x); x = self.l3(x); x = self.l4(x)\n",
        "        x = nn.functional.avg_pool2d(x, 4)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "0APQhDDA0gtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimSiam(nn.Module):\n",
        "    def __init__(self, backbone):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.projection = nn.Sequential(\n",
        "            nn.Linear(512, 2048, bias=False), nn.BatchNorm1d(2048), nn.ReLU(),\n",
        "            nn.Linear(2048, 2048, bias=False), nn.BatchNorm1d(2048), nn.ReLU(),\n",
        "            nn.Linear(2048, 2048, bias=False), nn.BatchNorm1d(2048, affine=False)\n",
        "        )\n",
        "        self.predictor = nn.Sequential(\n",
        "            nn.Linear(2048, 512, bias=False), nn.BatchNorm1d(512), nn.ReLU(),\n",
        "            nn.Linear(512, 2048)\n",
        "        )\n",
        "    def forward(self, x1, x2):\n",
        "        z1, z2 = self.projection(self.backbone(x1)), self.projection(self.backbone(x2))\n",
        "        p1, p2 = self.predictor(z1), self.predictor(z2)\n",
        "        return p1, p2, z1.detach(), z2.detach()\n",
        "\n",
        "def loss_fn(p, z):\n",
        "    p = nn.functional.normalize(p, dim=1)\n",
        "    z = nn.functional.normalize(z, dim=1)\n",
        "    return -(p * z).sum(dim=1).mean()\n"
      ],
      "metadata": {
        "id": "N8xa7i8O0mN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "backbone = ResNet18().to(device)\n",
        "model = SimSiam(backbone).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.06, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "\n",
        "print(\"\\nStarting SimSiam pre-training \")\n",
        "model.train()\n",
        "for epoch in range(1, 101):\n",
        "    total_loss = 0.0\n",
        "    for (view1, view2), _ in train_loader:\n",
        "        view1, view2 = view1.to(device), view2.to(device)\n",
        "        p1, p2, z1, z2 = model(view1, view2)\n",
        "        loss = 0.5 * (loss_fn(p1, z2) + loss_fn(p2, z1))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch:3d}/100 | Loss: {avg_loss:.4f}\")\n",
        "\n",
        "print(\"Pre-training finished!\\n\")\n"
      ],
      "metadata": {
        "id": "sUBzKIth0uLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sup = CIFAR10('./data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.RandomCrop(32, padding=4),\n",
        "                        transforms.RandomHorizontalFlip(),\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.4914,0.4822,0.4465),(0.2023,0.1994,0.2010))\n",
        "                    ]))\n",
        "test_sup = CIFAR10('./data', train=False, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.4914,0.4822,0.4465),(0.2023,0.1994,0.2010))\n",
        "                   ]))\n",
        "\n",
        "train_loader_sup = DataLoader(train_sup, batch_size=512, shuffle=True, num_workers=2, pin_memory=True)\n",
        "test_loader_sup  = DataLoader(test_sup,  batch_size=512, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "backbone.eval()\n",
        "for p in backbone.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "classifier = nn.Linear(512, 10).to(device)\n",
        "opt_clf = optim.SGD(classifier.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print(\"Training linear classifier\")\n",
        "for epoch in range(20):\n",
        "    classifier.train()\n",
        "    for x, y in train_loader_sup:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        loss = criterion(classifier(backbone(x)), y)\n",
        "        opt_clf.zero_grad()\n",
        "        loss.backward()\n",
        "        opt_clf.step()\n",
        "    print(f\"Linear epoch {epoch+1}/20 done\")"
      ],
      "metadata": {
        "id": "OEH5Mzy20zCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.eval()\n",
        "correct = total = 0\n",
        "with torch.no_grad():\n",
        "    for x, y in test_loader_sup:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        preds = classifier(backbone(x)).argmax(1)\n",
        "        correct += (preds == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "acc = 100 * correct / total\n",
        "print(f\"\\nFINAL TEST ACCURACY: {acc:.2f}%\")\n",
        "print(\"You just completed your first self-supervised learning project!\")"
      ],
      "metadata": {
        "id": "kM6aqXuW03pA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}